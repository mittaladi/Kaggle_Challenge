{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SML BONUS ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from skimage import feature\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import naive_bayes as nb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd \n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "import sklearn.preprocessing as prp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE PATH OF DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\IIITD\\\\2nd Sem\\\\SML\\\\Assignments\\\\Bonus\\\\cse342-542-bonus\\\\bonus_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_dict():\n",
    "    data={}\n",
    "    with open(path + '\\\\sml_train.csv') as csvfile:\n",
    "        reader=csv.reader(csvfile, skipinitialspace=True, quotechar=\"'\")\n",
    "        for row in reader:\n",
    "            data[row[0]]=row[1:]\n",
    "    del data['Id']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data():\n",
    "    images = []\n",
    "    filename_list = []\n",
    "    folder = path + \"\\\\sml_train\"\n",
    "    for filename in os.listdir(folder):\n",
    "        \n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            filename_list.append(filename)\n",
    "\n",
    "    return images, filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data_hsv():\n",
    "    images = []\n",
    "    filename_list = []\n",
    "    folder = path + \"\\\\sml_train\"\n",
    "    for filename in os.listdir(folder):\n",
    "        \n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            filename_list.append(filename)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data_gray():\n",
    "    images = []\n",
    "    filename_list = []\n",
    "    folder = path + \"\\\\sml_train\"\n",
    "    for filename in os.listdir(folder):\n",
    "        \n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            filename_list.append(filename)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data():\n",
    "    images = []\n",
    "    filename_list =[]\n",
    "    folder = path + \"/sml_test\"\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            filename_list.append(filename)\n",
    "    return images,filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data_hsv():\n",
    "    images = []\n",
    "    filename_list =[]\n",
    "    folder = path + \"/sml_test\"\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            filename_list.append(filename)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data_gray():\n",
    "    images = []\n",
    "    filename_list =[]\n",
    "    folder = path + \"/sml_test\"\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            filename_list.append(filename)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GETTING DATA READY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_dict = read_label_dict()\n",
    "train_data, filename_list = read_train_data()\n",
    "train_data_gray = read_train_data_gray()\n",
    "test_data, filename_list_test = read_test_data()\n",
    "test_data_gray = read_test_data_gray()\n",
    "train_data_hsv = read_train_data_hsv() \n",
    "test_data_hsv = read_test_data_hsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "for i in filename_list:\n",
    "    label_list.append(label_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HSV PIXEL INTENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_features = np.zeros((len(train_data),12288))\n",
    "train_data_hsv = np.array(train_data_hsv)\n",
    "for i in range(0,len(train_data_hsv)):\n",
    "    hsv_features[i] = np.ravel(train_data_hsv[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_features_test = np.zeros((len(test_data),12288))\n",
    "test_data_hsv = np.array(test_data_hsv)\n",
    "for i in range(0,len(test_data_hsv)):\n",
    "    hsv_features_test[i] = np.ravel(test_data_hsv[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RGB PIXEL INTENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_features = np.zeros((len(train_data),12288))\n",
    "train_data = np.array(train_data)\n",
    "for i in range(0,len(train_data)):\n",
    "    intensity_features[i] = np.ravel(train_data[i])\n",
    "#    intensity_features[i] = prp.scale(intensity_features[i])\n",
    "#intensity_features = np.ravel(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_features_test = np.zeros((len(test_data),12288))\n",
    "test_data = np.array(test_data)\n",
    "for i in range(0,len(test_data)):\n",
    "    intensity_features_test[i] = np.ravel(test_data[i])\n",
    "    #intensity_features_test[i] = prp.scale(intensity_features_test[i])\n",
    "#intensity_features = np.ravel(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discrip = []\n",
    "for i in range(0,len(train_data)):\n",
    "    fd = hog(train_data[i],orientations=8,pixels_per_cell=(16,16),cells_per_block=(4,4),block_norm='L2')\n",
    "    #img = train_data[i].reshape(64,-1)\n",
    "    #lbp = feature.local_binary_pattern(img,256, 3, method=\"uniform\")\n",
    "    #hist = np.histogram(lbp , bins=128)\n",
    "    #discriptor = train_data[i].flatten()\n",
    "    #discriptor = PCA(n_components=64).fit_transform(discriptor)\n",
    "    \n",
    "    #final_fd = np.concatenate((fd,discriptor))\n",
    "    \n",
    "    discrip.append(fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrip_test = []\n",
    "for i in range(0,len(test_data)):\n",
    "    fd = hog(test_data[i],orientations=8,pixels_per_cell=(16,16),cells_per_block=(4,4),block_norm='L2')\n",
    "#     img = test_data[i].reshape(64,-1)\n",
    "#     lbp = feature.local_binary_pattern(img,256, 3, method=\"uniform\")\n",
    "#     hist = np.histogram(lbp , bins=128)\n",
    "#     discriptor = hist[0]\n",
    "#     final_fd = np.concatenate((fd,discriptor))\n",
    "    discrip_test.append(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_features = prp.quantile_transform(hsv_features)\n",
    "#hsv_features = prp.scale(hsv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_features_test = prp.quantile_transform(hsv_features_test)\n",
    "#hsv_features_test = prp.scale(hsv_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_features = prp.quantile_transform(intensity_features)\n",
    "#intensity_features = prp.scale(intensity_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_features_test = prp.quantile_transform(intensity_features_test)\n",
    "#intensity_features_test = prp.scale(intensity_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrip = prp.quantile_transform(discrip)\n",
    "#discrip = prp.scale(discrip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrip_test = prp.quantile_transform(discrip_test)\n",
    "#discrip_test = prp.scale(discrip_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIMENSIONALITY REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40).fit(hsv_features)\n",
    "hsv_features_pca = pca.transform(hsv_features)\n",
    "hsv_features_pca_test = pca.transform(hsv_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40).fit(intensity_features)\n",
    "intensity_features_pca = pca.transform(intensity_features)\n",
    "intensity_features_pca_test = pca.transform(intensity_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40).fit(discrip)\n",
    "train_hog_pca = pca.transform(discrip)\n",
    "test_hog_pca = pca.transform(discrip_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbp_dis_lis = []\n",
    "# for i in range(0,len(train_data)):\n",
    "#     #img = train_data_gray[i].reshape(64,-1)\n",
    "#     lbp = feature.local_binary_pattern(train_data_gray[i],64, 3, method=\"uniform\")\n",
    "# #    hist = np.histogram(lbp , bins=128)\n",
    "#  #   discriptor = hist[0]\n",
    "#     lbp = lbp.flatten()\n",
    "#     lbp_dis_lis.append(lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbp_dis_lis_test = []\n",
    "# for i in range(0,len(test_data)):\n",
    "#     #img = train_data_gray[i].reshape(64,-1)\n",
    "#     lbp = feature.local_binary_pattern(test_data_gray[i],64, 3, method=\"uniform\")\n",
    "# #    hist = np.histogram(lbp , bins=128)\n",
    "#  #   discriptor = hist[0]\n",
    "#     lbp = lbp.flatten()\n",
    "#     lbp_dis_lis_test.append(lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=30).fit(lbp_dis_lis)\n",
    "# train_lbp_pca = pca.transform(lbp_dis_lis)\n",
    "\n",
    "# test_lbp_pca = pca.transform(lbp_dis_lis_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = np.concatenate((train_hog_pca,intensity_features_pca,hsv_features_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = np.concatenate((test_hog_pca,intensity_features_pca_test,hsv_features_pca_test),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 120)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "         final_train, label_list, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression 0.3462\n"
     ]
    }
   ],
   "source": [
    "logis_clf = LogisticRegression().fit(final_train , label_list)\n",
    "logis_acc = logis_clf.score(final_train , label_list)\n",
    "pred = logis_clf.predict(final_test)\n",
    "print('accuracy for logistic regression' , logis_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAUSSIAN NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for naive bayes 0.368\n"
     ]
    }
   ],
   "source": [
    "naive_clf = nb.GaussianNB().fit(final_train , label_list)\n",
    "naive_acc = naive_clf.score(final_train , label_list)\n",
    "pred = naive_clf.predict(final_test)\n",
    "print('accuracy for naive bayes' , naive_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for support vector machine 0.043666666666666666\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(gamma=\"auto\" , decision_function_shape='ovo').fit(x_train,y_train)\n",
    "svm_acc = svm_clf.score(x_test,y_test)\n",
    "print('accuracy for support vector machine' , svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for support vector machine 0.3382\n"
     ]
    }
   ],
   "source": [
    "linearSVC_clf = LinearSVC().fit(discrip , label_list)\n",
    "pred = linearSVC_clf.predict(discrip_test)\n",
    "svm_acc = linearSVC_clf.score(discrip , label_list)\n",
    "print('accuracy for support vector machine' , svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for support vector machine 0.2806666666666667\n"
     ]
    }
   ],
   "source": [
    "svm_acc = linearSVC_clf.score(x_test,y_test)\n",
    "print('accuracy for support vector machine' , svm_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(learning_rate=0.1,n_estimators=500,max_depth=8,min_child_weight=3,gamma=0.2,\n",
    "                              subsample=0.6,colsample_bytree=1.0,objective='binary:logistic',nthread=4,scale_pos_weight=1,\n",
    "                              seed=27).fit(final_train , label_list)\n",
    "pred = xgb_model.pred(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.456\n"
     ]
    }
   ],
   "source": [
    "RF_clf = RandomForestClassifier(n_estimators= 500, random_state=42).fit(x_train,y_train)\n",
    "print(RF_clf.score(x_test , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MitTal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "RF_clf = RandomForestClassifier(n_estimators= 500, random_state=42).fit(final_train , label_list)\n",
    "pred = RF_clf.predict(final_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"model_randomForest\"\n",
    "pickle.dump(RF_clf , open(file , \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename_list_test = np.array(filename_list_test)\n",
    "combined = np.vstack((filename_list_test, pred)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"output.csv\",combined , delimiter=',' , header='Id,Category',fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
